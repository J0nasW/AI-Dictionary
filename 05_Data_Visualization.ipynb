{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Extended AI Dictionary\n",
    "This notebook requires a running instance of the neo4j Graph Database with all the data from the steps before loaded and a built core dictionary. It will extend the core dictionary with the data from the graph database and save it as a new dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# register tqdm with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from helper.keyword_helper import get_tsne_coordinates, representation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PATH = \"data/dictionaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dictionary size: (25000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load the core &  extended dictionary that was produced by the 03b_Extended_Dictionary_Helper.py script\n",
    "dict_df = pd.read_csv(f\"{DICT_PATH}/dictionary.csv\").sample(25000, random_state=42)\n",
    "print(f\"Combined dictionary size: {dict_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cso_core key phrases: 76\n",
      "Number of cso_extended key phrases: 3461\n",
      "Number of cso key phrases in total: 3537\n",
      "Number of method_core key phrases: 289\n",
      "Number of method_extended key phrases: 10982\n",
      "Number of method key phrases in total: 11271\n",
      "Number of task_core key phrases: 149\n",
      "Number of task_extended key phrases: 2482\n",
      "Number of task key phrases in total: 2631\n",
      "Number of dataset_core key phrases: 1008\n",
      "Number of dataset_extended key phrases: 6553\n",
      "Number of dataset key phrases in total: 7561\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of cso_core key phrases: {len(dict_df[(dict_df['dict'] == 'core') & (dict_df['source'] == 'cso')])}\")\n",
    "print(f\"Number of cso_extended key phrases: {len(dict_df[(dict_df['dict'] == 'extended') & (dict_df['source'] == 'cso')])}\")\n",
    "print(f\"Number of cso key phrases in total: {len(dict_df[dict_df['source'] == 'cso'])}\")\n",
    "\n",
    "print(f\"Number of method_core key phrases: {len(dict_df[(dict_df['dict'] == 'core') & (dict_df['source'] == 'method')])}\")\n",
    "print(f\"Number of method_extended key phrases: {len(dict_df[(dict_df['dict'] == 'extended') & (dict_df['source'] == 'method')])}\")\n",
    "print(f\"Number of method key phrases in total: {len(dict_df[dict_df['source'] == 'method'])}\")\n",
    "\n",
    "print(f\"Number of task_core key phrases: {len(dict_df[(dict_df['dict'] == 'core') & (dict_df['source'] == 'task')])}\")\n",
    "print(f\"Number of task_extended key phrases: {len(dict_df[(dict_df['dict'] == 'extended') & (dict_df['source'] == 'task')])}\")\n",
    "print(f\"Number of task key phrases in total: {len(dict_df[dict_df['source'] == 'task'])}\")\n",
    "\n",
    "print(f\"Number of dataset_core key phrases: {len(dict_df[(dict_df['dict'] == 'core') & (dict_df['source'] == 'dataset')])}\")\n",
    "print(f\"Number of dataset_extended key phrases: {len(dict_df[(dict_df['dict'] == 'extended') & (dict_df['source'] == 'dataset')])}\")\n",
    "print(f\"Number of dataset key phrases in total: {len(dict_df[dict_df['source'] == 'dataset'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc8316bcf1a4544a3c15df529513d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_core: (25000, 768)\n",
      "Shape of example from x_core: (768,)\n",
      "===> Finding 600 nearest neighbors using Annoy approximate search using cosine distance...\n",
      "   --> Time elapsed: 41.46 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 3.60 seconds\n",
      "===> Calculating PCA-based initialization...\n",
      "   --> Time elapsed: 0.77 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "TSNE(early_exaggeration=12, n_jobs=8, verbose=True)\n",
      "--------------------------------------------------------------------------------\n",
      "===> Running optimization with exaggeration=12.00, lr=2083.33 for 250 iterations...\n",
      "Iteration   50, KL divergence 4.8853, 50 iterations in 1.5375 sec\n",
      "Iteration  100, KL divergence 4.9391, 50 iterations in 1.5100 sec\n",
      "Iteration  150, KL divergence 4.9395, 50 iterations in 1.5217 sec\n",
      "Iteration  200, KL divergence 4.9394, 50 iterations in 1.6486 sec\n",
      "Iteration  250, KL divergence 4.9394, 50 iterations in 1.6470 sec\n",
      "   --> Time elapsed: 7.87 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=25000.00 for 500 iterations...\n",
      "Iteration   50, KL divergence 1.8843, 50 iterations in 1.7061 sec\n",
      "Iteration  100, KL divergence 1.6538, 50 iterations in 2.2223 sec\n",
      "Iteration  150, KL divergence 1.5556, 50 iterations in 2.8923 sec\n",
      "Iteration  200, KL divergence 1.4951, 50 iterations in 3.9448 sec\n",
      "Iteration  250, KL divergence 1.4571, 50 iterations in 4.5212 sec\n",
      "Iteration  300, KL divergence 1.4276, 50 iterations in 5.2191 sec\n",
      "Iteration  350, KL divergence 1.4064, 50 iterations in 5.9081 sec\n",
      "Iteration  400, KL divergence 1.3901, 50 iterations in 6.4153 sec\n",
      "Iteration  450, KL divergence 1.3760, 50 iterations in 7.1196 sec\n",
      "Iteration  500, KL divergence 1.3646, 50 iterations in 7.6662 sec\n",
      "   --> Time elapsed: 47.62 seconds\n",
      "Shape of keyword_embeddings_tsne_2d_core: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "tsne_dict_df = dict_df.copy()\n",
    "\n",
    "tsne_dict_df[\"embedding\"] = tsne_dict_df[\"embedding\"].progress_apply(ast.literal_eval)\n",
    "x = np.array(tsne_dict_df[\"embedding\"].tolist())\n",
    "print(f\"Shape of x_core: {x.shape}\")\n",
    "print(f\"Shape of example from x_core: {x[0].shape}\")\n",
    "\n",
    "keyword_embeddings_tsne_2d = get_tsne_coordinates(x)\n",
    "print(f\"Shape of keyword_embeddings_tsne_2d_core: {keyword_embeddings_tsne_2d.shape}\")\n",
    "\n",
    "# Add the TSNE coordinates to the dataframe\n",
    "tsne_dict_df[\"tsne_x\"] = keyword_embeddings_tsne_2d[:,0]\n",
    "tsne_dict_df[\"tsne_y\"] = keyword_embeddings_tsne_2d[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 164 clusters\n"
     ]
    }
   ],
   "source": [
    "# Clustering\n",
    "keyword_embeddings_hdbscan = HDBSCAN(\n",
    "    min_cluster_size = 50,\n",
    "    min_samples = 5,\n",
    "    metric=\"euclidean\",\n",
    "    # cluster_selection_method=\"eom\",\n",
    "    cluster_selection_method=\"leaf\",\n",
    "    prediction_data=True,\n",
    "    core_dist_n_jobs=8,\n",
    ").fit(keyword_embeddings_tsne_2d)\n",
    "print(f\"Got {len(set(keyword_embeddings_hdbscan.labels_))} clusters\")\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "tsne_dict_df[\"cluster\"] = keyword_embeddings_hdbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>[fewer prior information, pretrained residual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[similar ensemble approach, original ensemble,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[purely transformer-based model, enhanced tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[aware loss function, enhanced loss function, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[one-shot network, few-shot classification tas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                            keyword\n",
       "0       -1  [fewer prior information, pretrained residual ...\n",
       "1        0  [similar ensemble approach, original ensemble,...\n",
       "2        1  [purely transformer-based model, enhanced tran...\n",
       "3        2  [aware loss function, enhanced loss function, ...\n",
       "4        3  [one-shot network, few-shot classification tas..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba5f7db664f4ab792ae19ce506c2119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating representations...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilinski/.local/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>keyword</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>[fewer prior information, pretrained residual ...</td>\n",
       "      <td>computational learning model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[similar ensemble approach, original ensemble,...</td>\n",
       "      <td>ubc machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[purely transformer-based model, enhanced tran...</td>\n",
       "      <td>learning models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[aware loss function, enhanced loss function, ...</td>\n",
       "      <td>open-source computational recursive neural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[one-shot network, few-shot classification tas...</td>\n",
       "      <td>Artificial intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                            keyword  \\\n",
       "0       -1  [fewer prior information, pretrained residual ...   \n",
       "1        0  [similar ensemble approach, original ensemble,...   \n",
       "2        1  [purely transformer-based model, enhanced tran...   \n",
       "3        2  [aware loss function, enhanced loss function, ...   \n",
       "4        3  [one-shot network, few-shot classification tas...   \n",
       "\n",
       "                               representation  \n",
       "0                computational learning model  \n",
       "1                        ubc machine learning  \n",
       "2                             learning models  \n",
       "3  open-source computational recursive neural  \n",
       "4                     Artificial intelligence  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>source</th>\n",
       "      <th>embedding</th>\n",
       "      <th>dict</th>\n",
       "      <th>trie_id</th>\n",
       "      <th>tsne_x</th>\n",
       "      <th>tsne_y</th>\n",
       "      <th>cluster</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standard ultrasound transducer</td>\n",
       "      <td>dataset</td>\n",
       "      <td>[0.5186449289321899, -0.09616893529891968, 0.5...</td>\n",
       "      <td>extended</td>\n",
       "      <td>446922</td>\n",
       "      <td>-13.350599</td>\n",
       "      <td>35.724459</td>\n",
       "      <td>124</td>\n",
       "      <td>open-source covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meaningful clustering measure</td>\n",
       "      <td>task</td>\n",
       "      <td>[0.055283308029174805, 0.021428877487778664, 0...</td>\n",
       "      <td>extended</td>\n",
       "      <td>318547</td>\n",
       "      <td>-61.618585</td>\n",
       "      <td>47.160939</td>\n",
       "      <td>11</td>\n",
       "      <td>classification and classification problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fewer prior information</td>\n",
       "      <td>cso</td>\n",
       "      <td>[0.16202954947948456, -0.02446877583861351, -0...</td>\n",
       "      <td>extended</td>\n",
       "      <td>61882</td>\n",
       "      <td>0.868736</td>\n",
       "      <td>-61.612423</td>\n",
       "      <td>-1</td>\n",
       "      <td>computational learning model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proper dataset</td>\n",
       "      <td>task</td>\n",
       "      <td>[-0.03730485215783119, -0.32432374358177185, -...</td>\n",
       "      <td>extended</td>\n",
       "      <td>321393</td>\n",
       "      <td>12.513974</td>\n",
       "      <td>-19.342143</td>\n",
       "      <td>143</td>\n",
       "      <td>artificial intelligence in applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limiting distribution</td>\n",
       "      <td>task</td>\n",
       "      <td>[-0.3170706033706665, -0.2181326448917389, -0....</td>\n",
       "      <td>extended</td>\n",
       "      <td>291323</td>\n",
       "      <td>-14.498732</td>\n",
       "      <td>-60.521299</td>\n",
       "      <td>35</td>\n",
       "      <td>human-machine interfaces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          keyword   source  \\\n",
       "0  standard ultrasound transducer  dataset   \n",
       "1   meaningful clustering measure     task   \n",
       "2         fewer prior information      cso   \n",
       "3                  proper dataset     task   \n",
       "4           limiting distribution     task   \n",
       "\n",
       "                                           embedding      dict  trie_id  \\\n",
       "0  [0.5186449289321899, -0.09616893529891968, 0.5...  extended   446922   \n",
       "1  [0.055283308029174805, 0.021428877487778664, 0...  extended   318547   \n",
       "2  [0.16202954947948456, -0.02446877583861351, -0...  extended    61882   \n",
       "3  [-0.03730485215783119, -0.32432374358177185, -...  extended   321393   \n",
       "4  [-0.3170706033706665, -0.2181326448917389, -0....  extended   291323   \n",
       "\n",
       "      tsne_x     tsne_y  cluster                              representation  \n",
       "0 -13.350599  35.724459      124                           open-source covid  \n",
       "1 -61.618585  47.160939       11  classification and classification problems  \n",
       "2   0.868736 -61.612423       -1                computational learning model  \n",
       "3  12.513974 -19.342143      143     artificial intelligence in applications  \n",
       "4 -14.498732 -60.521299       35                    human-machine interfaces  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate representations for each cluster\n",
    "cluster_keywords = tsne_dict_df.groupby('cluster')['keyword'].apply(list).reset_index()\n",
    "display(cluster_keywords.head())\n",
    "\n",
    "# Apply the function representation_generator to the list of keywords for each cluster\n",
    "keywords_list = cluster_keywords['keyword'].tolist()\n",
    "cluster_keywords['representation'] = representation_generator(keywords_list)\n",
    "display(cluster_keywords.head())\n",
    "\n",
    "# Assign each cluster its representation\n",
    "tsne_dict_df = tsne_dict_df.merge(cluster_keywords[['cluster', 'representation']], on='cluster', how='left')\n",
    "display(tsne_dict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all rows with cluster = -1 to noise in column representation\n",
    "tsne_dict_df.loc[tsne_dict_df['cluster'] == -1, 'representation'] = 'noise'\n",
    "\n",
    "# Make a plotly scatter plot of all keywords. Color the keywords by their cluster label and group them by their source dictionary\n",
    "fig = px.scatter(\n",
    "    tsne_dict_df,\n",
    "    x=\"tsne_x\",\n",
    "    y=\"tsne_y\",\n",
    "    color=\"representation\",\n",
    "    hover_name=\"keyword\",\n",
    "    symbol=\"dict\",\n",
    "    symbol_map={\n",
    "        \"core\": \"circle\",\n",
    "        \"extended\": \"cross\",\n",
    "    },\n",
    "    hover_data=[\"keyword\", \"cluster\", \"representation\", \"dict\", \"source\"])\n",
    "# Save the plot\n",
    "fig.write_html(\"plots/keyword_embeddings.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
