{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Extended AI Dictionary\n",
    "This notebook requires a running instance of the neo4j Graph Database with all the data from the steps before loaded and a built core dictionary. It will extend the core dictionary with the data from the graph database and save it as a new dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# register tqdm with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from helper.keyword_helper import get_tsne_coordinates, representation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PATH = \"data/dictionaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the core &  extended dictionary that was produced by the 03b_Extended_Dictionary_Helper.py script\n",
    "core_dict_df = pd.read_csv(DICT_PATH + \"/core_dictionary.csv\")\n",
    "ext_dict_df = pd.read_csv(DICT_PATH + \"/extended_dictionary.csv\")\n",
    "neg_keywords_df = pd.read_csv(DICT_PATH + \"/negative_keywords.csv\")\n",
    "print(\"Core dictionary size: \", core_dict_df.shape)\n",
    "print(\"Extended dictionary size: \", ext_dict_df.shape)\n",
    "print(\"Negative keywords size: \", neg_keywords_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the core and extended dictionary dataframes into one by adding a column that indicates the source dict\n",
    "core_dict_df[\"dict\"] = \"core\"\n",
    "ext_dict_df[\"dict\"] = \"extended\"\n",
    "\n",
    "# Combine the core and extended dictionary dataframes into one. Take the columns \"keyword\", \"source\" and \"embedding\" from the core_dict and the column \"keyword\", \"source\" and \"embedding\" from the ext_dict\n",
    "dict_df = pd.concat([core_dict_df[[\"keyword\", \"source\", \"embedding\", \"dict\"]], ext_dict_df[[\"keyword\", \"source\", \"embedding\", \"dict\"]]], ignore_index=True)\n",
    "dict_df = dict_df.reset_index(drop=True)\n",
    "display(dict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make word clouds for each of the four sources in the dict_df\n",
    "# Create a list of the four sources\n",
    "sources = dict_df[\"source\"].unique().tolist()\n",
    "\n",
    "# Make a word cloud for each of the four sources\n",
    "for source in sources:\n",
    "    # Create a dataframe that only contains the keywords of the current source\n",
    "    source_df = dict_df[dict_df[\"source\"] == source]\n",
    "    # Create a list of the keywords for the current source\n",
    "    keywords = source_df[\"keyword\"].tolist()\n",
    "    # Create a list of the embeddings for the current source\n",
    "    embeddings = source_df[\"embedding\"].tolist()\n",
    "    # Create a list of the embeddings for the current source\n",
    "    dicts = source_df[\"dict\"].tolist()\n",
    "    # Create a word cloud for the current source\n",
    "    representation_generator(keywords, embeddings, dicts, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE for the embeddings\n",
    "x = np.array(dict_df[\"embedding\"].tolist())\n",
    "print(f\"Shape of x_core: {x.shape}\")\n",
    "print(f\"Shape of example from x_core: {x[0].shape}\")\n",
    "\n",
    "keyword_embeddings_tsne_2d = get_tsne_coordinates(x)\n",
    "print(f\"Shape of keyword_embeddings_tsne_2d_core: {keyword_embeddings_tsne_2d.shape}\")\n",
    "\n",
    "# Add the TSNE coordinates to the dataframe\n",
    "dict_df[\"tsne_x\"] = keyword_embeddings_tsne_2d[:,0]\n",
    "dict_df[\"tsne_y\"] = keyword_embeddings_tsne_2d[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "keyword_embeddings_hdbscan = HDBSCAN(\n",
    "    min_cluster_size = 30,\n",
    "    min_samples = 5,\n",
    "    metric=\"euclidean\",\n",
    "    # cluster_selection_method=\"eom\",\n",
    "    cluster_selection_method=\"leaf\",\n",
    "    prediction_data=True,\n",
    "    core_dist_n_jobs=8,\n",
    ").fit(keyword_embeddings_tsne_2d)\n",
    "print(f\"Got {len(set(keyword_embeddings_hdbscan.labels_))} clusters\")\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "dict_df[\"cluster\"] = keyword_embeddings_hdbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate representations for each cluster\n",
    "cluster_keywords = dict_df.groupby('cluster')['keyword'].apply(list).reset_index()\n",
    "\n",
    "# Apply the function representation_generator to each cluster\n",
    "cluster_keywords['representation'] = cluster_keywords['keyword'].progress_apply(lambda x: representation_generator(x))\n",
    "\n",
    "display(cluster_keywords.head())\n",
    "\n",
    "# Assign each cluster its representation\n",
    "dict_df = dict_df.merge(cluster_keywords[['cluster', 'representation']], on='cluster', how='left')\n",
    "display(dict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plotly scatter plot of all keywords. Color the keywords by their cluster label and group them by their source dictionary\n",
    "fig = px.scatter(\n",
    "    dict_df,\n",
    "    x=\"tsne_x\",\n",
    "    y=\"tsne_y\",\n",
    "    color=\"cluster\",\n",
    "    symbol=\"dict\",\n",
    "    hover_data=[\"keyword\", \"cluster\", \"dict\"])\n",
    "# Save the plot\n",
    "fig.write_html(\"plots/keyword_embeddings.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
